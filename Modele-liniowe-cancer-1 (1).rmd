---
title: "Modele liniowe cancer"
author: "Grzegorz Kuriata, Adam Pater"
date: "18 06 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(ResourceSelection)
library(statmod)
```

```{r}
cancer <- read.csv("cancer.csv")
```

Będziemy zajmować się zbiorem danych zawierającym 569 obserwacji. Badano diagnozę raka piersi przez wzgląd na różne czynniki. Na początku spójrzmy na opis naszych predyktorów.

Nazwa zmiennej   | Opis                                                                                   |
-----------------|----------------------------------------------------------------------------------------|
`diagnosis`      | Diagnoza (M - złośliwy, B - łagodny)                                                   |
`area_mean`      | Średni obszar jądra komórkowego                                                        |
`texture_mean`   | Średnia tekstura (odchylenie standardowe od wartości skali szarości) jądra komórkowego |
`smoothness_mean`| gładkość (lokalna zmienność długości promieni) jądra komórkowego                       |

```{r}
str(cancer)
```

Zmienna `diagnosis` jest zmienną charakterystyczną, więc zmieniamy ją na liczbową.

```{r}
cancer <- cancer %>% mutate(diagnosis = as.integer(ifelse(diagnosis == "M", "0", "1")))
```

Podsumujmy nasze dane

```{r}
summary(cancer)
```

*Ustalimy czy istnieje asocjacja między diagnozą raka piersi, a zmiennymi `area_mean`, `texture_mean`, `smoothness_mean`.

*Sprawdzimy jak zachowują się modele z różną kombinacją predyktorów.

*Ile zdiagnozowanych osób mających średni obszar jądra komórkowego większy niż 800 ma większą szansę na diagnozę złośliwego raka piersi, a ile poniżej ?



W tym momencie sprawdźmy jak wygladają rozkłady naszych zmiennych. W tym miejscu tworzymy histogramy jak również histogramy, w których logarytmujemy nasze predyktory, żeby od razu móc zobaczyć, czy wykresy się poprawią.

```{r}
rad <- ggplot(data = cancer, aes(x = area_mean)) + geom_histogram()
rad_log <- ggplot(data = cancer, aes(x = log2(area_mean))) + geom_histogram()
tex <- ggplot(data = cancer, aes(x = texture_mean)) + geom_histogram()
tex_log <- ggplot(data = cancer, aes(x = log2(texture_mean))) + geom_histogram()
smo <- ggplot(data = cancer, aes(x = smoothness_mean)) + geom_histogram()
smo_log <- ggplot(data = cancer, aes(x = log2(smoothness_mean))) + geom_histogram()

grid.arrange(rad, rad_log, tex, tex_log,smo,smo_log, nrow=3)
```

Wniosek: Nałożenie logarytmu na nasze zmienne dały poprawe dla zmiennej `area_mean` oraz `texture_mean` i nieznacznie dla zmiennej `smoothness_mean`. Budując modele będziemy zwracać uwagę, czy zmienne zlogarytmowane poprawią wyniki modelu.


Patrząc na nieprzekształcony histogram zmiennej 'area_mean' odpowiedzmy sobie na pytanie, ile osób .

```{r}
wpow_750 <- cancer[which(cancer$area_mean >= 800 & cancer$diagnosis == 1), ]

length(wpow_750$diagnosis)
```

Jest 5 osób, które mają większą szansę na łagodnego raka piersi i ich średni obszar jądra komórkowego jest większy niż 800.

```{r}
wpow_750 <- cancer[which(cancer$area_mean >= 800 & cancer$diagnosis == 0), ]

length(wpow_750$diagnosis)
```

Jest 133 osób, które mają większą szansę na złośliwego raka piersi i ich średni obszar jądra komórkowego jest większy niż 800.

```{r}
wpon_750 <- cancer[which(cancer$area_mean < 800 & cancer$diagnosis == 1), ]

length(wpon_750$diagnosis)
```

Są 352 osoby, które mają większą szansę na łagodnego raka piersi i ich średni obszar jądra komórkowego jest wmniejszy niż 800.

```{r}
wpon_750 <- cancer[which(cancer$area_mean < 800 & cancer$diagnosis == 0), ]

length(wpon_750$diagnosis)
```

Jest 79 osób, które mają większą szansę na złośliwego raka piersi i ich średni obszar jądra komórkowego jest mniejszy niż 800.

```{r}
procent<- 113/(5+113)*100
procent

```

```{r}
procent2<-79/(352+79)*100
procent2

```

Wniosek: Około 95,8% osób mających średni obszar jądra komórkowego większy lub równy 800 mają większą szansę na diagnozę złośliwego raka piersi, natomiast poniżej około 18,3%.


Teraz zbudujemy modele.

```{r}
model_area <- glm(diagnosis~area_mean, data = cancer, family = "binomial")
summary(model_area)
```

```{r}
model_texture <- glm(diagnosis~texture_mean, data = cancer, family = "binomial")
summary(model_texture)
```

```{r}
model_smoothness <- glm(diagnosis~smoothness_mean, data = cancer, family = "binomial")
summary(model_smoothness)
```

Dewiancja wynosi 751.44 i jest większa od 568 stopni swobody. Może to świadczyć o zjawisku nadmiernej dyspersji lub niedopasowaniu modeli. Jednakże, na razie się tym nie przejmujemy, ponieważ końcowy model będzie zawierał więcej niż jeden predyktor. Zauważmy także, że AIC jest prawie dwa razy mniejsze dla modelu ze zmienną `area_mean` niż dla pozostałych. To może oznaczać, że zmienna `area_mean` lepiej definiuje model niż pozostałe dwie.

Zobaczmy jak wyglądają wykresy diagnostyczne modelu ze zmiennymi z większym AIC.

```{r}
par(mfrow=c(2,2))
plot(model_texture)
```


```{r}
par(mfrow=c(2,2))
plot(model_smoothness)
```

Jak możemy zauważyć, modele te nie są najlepiej dopasowane, ale nie są też źle dopasowane.

Zobaczmy jak będzie wyglądał końcowy model.

```{r}

model1<-glm(diagnosis~area_mean+smoothness_mean+texture_mean, data = cancer, family = "binomial")
summary(model1)
```

Wykonajmy jeszcze test Hosmera-Lameshowa.

```{r}
hoslem.test(cancer$diagnosis, fitted(model1))
```

Wygląda na to, że ten model jest dobrze dopasowany.
Sprawdźmy jeszcze modele ze zlogarytmowanymi zmiennymi `area_mean` oraz `texture_mean`.

```{r}
model2 <- glm(diagnosis~log2(area_mean)+smoothness_mean+texture_mean, data = cancer, family = "binomial")
summary(model2)
```

```{r}
hoslem.test(cancer$diagnosis, fitted(model2))
```

Ten model także jest dobrze dopasowany.

```{r}
model3 <- glm(diagnosis~log2(area_mean)+smoothness_mean+log2(texture_mean), data = cancer, family = "binomial")
summary(model3)
```

```{r}
hoslem.test(cancer$diagnosis, fitted(model3))
```

Patrząc na p-value, które w teście Hosmera-Lameshowa powinno być jak najwyższe okazuje się, że model ze zlogarytmowanymi zmiennymi `area_mean` oraz `texture_mean`wydaje się być najlepszym modelem.

Ostatecznie modelem końcowym zostaje "model3". Sprawdźmy jak wyglądają jego wykresy diagnostyczne.

```{r}
par(mfrow=c(2,2))
plot(model3)
```

Wykresy diagnostyczne potwierdzają nasze przypuszczenia, model ten jest dobrze dopasowany.


```{r}
residu1 = c()
predictor1 = c()
for (i in 1:10) {
  res <- qresid(model3)
  pred <- predict(model2, type='response')
  residu1 = c(residu1, res)
  predictor1 = c(predictor1, pred)
  
}
scatter.smooth(predictor1, residu1, col='gray')

```

Reszty kwantylowe pozwalają na lepszą diagnostykę modelu. Możemy zaobserwować dobre dopasowanie modelu, co potwierdza poprzednie testy.














